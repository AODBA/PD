{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in our last chapter that we have and army of methods to load data into a Pandas DataFrame. \n",
    "\n",
    "In this chapter we are going to talk about methods provided by Pandas to write data from a DataFrame onto a different Data Source/ Data Target.\n",
    "\n",
    "## Let`s beggin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrian</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Julia</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Julia</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Age\n",
       "0  Adrian   33\n",
       "1   Julia   21\n",
       "2   Julia   22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we imported Pandas \n",
    "## lets load one of the file we previously used to Load Data into a DataFrame \n",
    "\n",
    "my_df = pd.read_csv('DataSources\\my_csv.csv')\n",
    "\n",
    "my_df\n",
    "\n",
    "## Ok - all is good now, we have a DataFrame and let`s go thru some examples on how we can write data out of a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Name,Age\n",
      "0,Adrian,33\n",
      "1,Julia,21\n",
      "\n",
      "Name,Age\n",
      "Adrian,33\n",
      "Julia,21\n",
      "Julia,22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.to_csv('DataOut\\my_exported_csv.csv')\n",
    "\n",
    "## Ok - we have the DataFrame Exported into a csv format file \n",
    "\n",
    "## Lets look at it ! \n",
    "\n",
    "print(open('DataOut\\csv\\my_exported_csv.csv').read())\n",
    "\n",
    "## You can see we the index added as well to the file\n",
    "## let`s get rid of it \n",
    "\n",
    "my_df.to_csv('DataOut\\csv\\my_exported_csv.csv',index=False)\n",
    "\n",
    "## Lets look at it again \n",
    "\n",
    "print(open('DataOut\\csv\\my_exported_csv.csv').read())\n",
    "\n",
    "## Looks great - its clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data in CSV format and Zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ok this is a nice feature \n",
    "## for this the parameter compression that will hold a dict object\n",
    "## in this case we will call it compression_option and give it the method & archive_name\n",
    "\n",
    "compression_option = dict(method='zip', archive_name='my_exported_csv.csv')\n",
    "\n",
    "my_df.to_csv('DataOut\\csv\\my_exported_csv.zip',index=False, compression=compression_option)\n",
    "\n",
    "# Great ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data in CSV format and with custom field delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name@Age\n",
      "Adrian@33\n",
      "Julia@21\n",
      "Julia@22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.to_csv('DataOut\\csv\\my_exported_csv.csv')\n",
    "\n",
    "my_df.to_csv('DataOut\\csv\\my_exported_csv_custom.csv',index=False,sep='@')\n",
    "\n",
    "print(open('DataOut\\csv\\my_exported_csv_custom.csv').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Name\":{\"0\":\"Adrian\",\"1\":\"Julia\",\"2\":\"Julia\"},\"Age\":{\"0\":33,\"1\":21,\"2\":22}}\n"
     ]
    }
   ],
   "source": [
    "## we have our DF loaded \n",
    "## writing data into json format is as easy as it gets in pandas and take a guess whats the name ! Correct to_json()\n",
    "my_df\n",
    "\n",
    "my_df.to_json('DataOut\\my_exported_json.json')\n",
    "\n",
    "## read the file \n",
    "print(open('DataOut\\my_exported_json.json').read())\n",
    "\n",
    "## Again this index !! \n",
    "## Now in to_json() we have parameter called orient and this is a very powerfull parameter, he dictates the way the json \n",
    "## output will be constructed\n",
    "## Lets see it in action ! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Available orinet options are:\n",
    "- split\n",
    "- records\n",
    "- index\n",
    "- columns\n",
    "- values \n",
    "- table\n",
    "\n",
    "Depending on you use case you will choose the right one for you! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Name\":{\"0\":\"Adrian\",\"1\":\"Julia\",\"2\":\"Julia\"},\"Age\":{\"0\":33,\"1\":21,\"2\":22}}\n"
     ]
    }
   ],
   "source": [
    "## We will start with the default orient, which is 'columns', when we export to_json() from a dataframe\n",
    "\n",
    "my_df.to_json('DataOut\\json\\my_exported_json_columns.json')\n",
    "\n",
    "## read the file \n",
    "print(open('DataOut\\json\\my_exported_json_columns.json').read())\n",
    "\n",
    "# {\n",
    "#     \"Name\": {\n",
    "#         \"0\": \"Adrian\",\n",
    "#         \"1\": \"Julia\"\n",
    "#     },\n",
    "#     \"Age\": {\n",
    "#         \"0\": 33,\n",
    "#         \"1\": 21\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"columns\":[\"Name\",\"Age\"],\"index\":[0,1,2],\"data\":[[\"Adrian\",33],[\"Julia\",21],[\"Julia\",22]]}\n"
     ]
    }
   ],
   "source": [
    "## split\n",
    "\n",
    "my_df.to_json('DataOut\\json\\my_exported_json_split.json', orient='split')\n",
    "\n",
    "## read the file \n",
    "print(open('DataOut\\json\\my_exported_json_split.json').read())\n",
    "\n",
    "# {\n",
    "#     \"columns\": [\n",
    "#         \"Name\",\n",
    "#         \"Age\"\n",
    "#     ],\n",
    "#     \"index\": [\n",
    "#         0,\n",
    "#         1\n",
    "#     ],\n",
    "#     \"data\": [\n",
    "#         [\n",
    "#             \"Adrian\",\n",
    "#             33\n",
    "#         ],\n",
    "#         [\n",
    "#             \"Julia\",\n",
    "#             21\n",
    "#         ]\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Name\":\"Adrian\",\"Age\":33},{\"Name\":\"Julia\",\"Age\":21},{\"Name\":\"Julia\",\"Age\":22}]\n"
     ]
    }
   ],
   "source": [
    "## records - this might be the most used one\n",
    "\n",
    "my_df.to_json('DataOut\\json\\my_exported_json_records.json', orient='records')\n",
    "\n",
    "## read the file \n",
    "print(open('DataOut\\json\\my_exported_json_records.json').read())\n",
    "\n",
    "# [\n",
    "#     {\n",
    "#         \"Name\": \"Adrian\",\n",
    "#         \"Age\": 33\n",
    "#     },\n",
    "#     {\n",
    "#         \"Name\": \"Julia\",\n",
    "#         \"Age\": 21\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\":{\"Name\":\"Adrian\",\"Age\":33},\"1\":{\"Name\":\"Julia\",\"Age\":21},\"2\":{\"Name\":\"Julia\",\"Age\":22}}\n"
     ]
    }
   ],
   "source": [
    "## index - the index value will be the root of the element\n",
    "\n",
    "my_df.to_json('DataOut\\json\\my_exported_json_index.json', orient='index')\n",
    "\n",
    "## read the file \n",
    "print(open('DataOut\\json\\my_exported_json_index.json').read())\n",
    "\n",
    "# {\n",
    "#     \"0\": {\n",
    "#         \"Name\": \"Adrian\",\n",
    "#         \"Age\": 33\n",
    "#     },\n",
    "#     \"1\": {\n",
    "#         \"Name\": \"Julia\",\n",
    "#         \"Age\": 21\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"Adrian\",33],[\"Julia\",21],[\"Julia\",22]]\n"
     ]
    }
   ],
   "source": [
    "## values - very compact, if you don`t need the column - this is the one to go for \n",
    "my_df.to_json('DataOut\\json\\my_exported_json_values.json', orient='values')\n",
    "\n",
    "## read the file \n",
    "print(open('DataOut\\json\\my_exported_json_values.json').read())\n",
    "\n",
    "# [\n",
    "#     [\n",
    "#         \"Adrian\",\n",
    "#         33\n",
    "#     ],\n",
    "#     [\n",
    "#         \"Julia\",\n",
    "#         21\n",
    "#     ]\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"schema\":{\"fields\":[{\"name\":\"index\",\"type\":\"integer\"},{\"name\":\"Name\",\"type\":\"string\"},{\"name\":\"Age\",\"type\":\"integer\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"},\"data\":[{\"index\":0,\"Name\":\"Adrian\",\"Age\":33},{\"index\":1,\"Name\":\"Julia\",\"Age\":21},{\"index\":2,\"Name\":\"Julia\",\"Age\":22}]}\n"
     ]
    }
   ],
   "source": [
    "## table - maybe the most verbose of all, but very handy in some cases.\n",
    "\n",
    "my_df.to_json('DataOut\\json\\my_exported_json_table.json', orient='table')\n",
    "\n",
    "## read the file \n",
    "print(open('DataOut\\json\\my_exported_json_table.json').read())\n",
    "\n",
    "\n",
    "# {\n",
    "#     \"schema\": {\n",
    "#         \"fields\": [\n",
    "#             {\n",
    "#                 \"name\": \"index\",\n",
    "#                 \"type\": \"integer\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"name\": \"Name\",\n",
    "#                 \"type\": \"string\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"name\": \"Age\",\n",
    "#                 \"type\": \"integer\"\n",
    "#             }\n",
    "#         ],\n",
    "#         \"primaryKey\": [\n",
    "#             \"index\"\n",
    "#         ],\n",
    "#         \"pandas_version\": \"0.20.0\"\n",
    "#     },\n",
    "#     \"data\": [\n",
    "#         {\n",
    "#             \"index\": 0,\n",
    "#             \"Name\": \"Adrian\",\n",
    "#             \"Age\": 33\n",
    "#         },\n",
    "#         {\n",
    "#             \"index\": 1,\n",
    "#             \"Name\": \"Julia\",\n",
    "#             \"Age\": 21\n",
    "#         }\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Ok, we saw all the available orient optins and how the look, what about the other parameters ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also compress a json file using to_json() method\n",
    "\n",
    "compression_option = dict(method='zip', archive_name='my_exported_compressed.json')\n",
    "\n",
    "my_df.to_json('DataOut\\json\\my_exported_compressed.zip', orient='table', compression=compression_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## we can also play with the indentation defintion \n",
    "## we will the default orientation and we will give it a ridiculos value od 33\n",
    "\n",
    "my_df.to_json('DataOut\\json\\my_exported_json_indent.json', indent=33)\n",
    "\n",
    "## yeah it looks not to good , but this just shows that we can control this aspect as well ! \n",
    "\n",
    "# {\n",
    "#                                  \"Name\":{\n",
    "#                                                                   \"0\":\"Adrian\",\n",
    "#                                                                   \"1\":\"Julia\"\n",
    "#                                  },\n",
    "#                                  \"Age\":{\n",
    "#                                                                   \"0\":33,\n",
    "#                                                                   \"1\":21\n",
    "#                                  }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What next ? \n",
    "\n",
    "\n",
    "**to_sql()** - this method is very powerfull and allows us to interact directly with a Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Adrian', 33), (1, 'Julia', 21), (2, 'Julia', 22)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For this example we will use sqlalchemy module and create connection to a MariaDB on my localhost\n",
    "\n",
    "import sqlalchemy\n",
    "SQLALCHEMY_DATABASE_URI = 'mysql+pymysql://root:root@localhost/pandas'\n",
    "## Dont mind the very dificult password ! :)\n",
    "\n",
    "## Create the engine\n",
    "engine = sqlalchemy.create_engine(SQLALCHEMY_DATABASE_URI)\n",
    "\n",
    "## create a connection object - you will need to close \n",
    "conn = engine.connect().connection\n",
    "\n",
    "## the parameter name represents the table that we will use to write data to, if table does not exisit then\n",
    "## the table will be created\n",
    "my_df.to_sql(name='my_users', con=engine)\n",
    "\n",
    "## commit the data\n",
    "conn.commit()\n",
    "\n",
    "## Close connection \n",
    "conn.close()\n",
    "## Query the newly created Table \n",
    "engine.execute(\"select * from my_users\").fetchall()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Adrian', 33),\n",
       " (1, 'Julia', 21),\n",
       " (2, 'Julia', 22),\n",
       " (0, 'Adrian', 33),\n",
       " (1, 'Julia', 21),\n",
       " (2, 'Julia', 22)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## What is the Table exists ? \n",
    "## well fo this we have the parameter if_exists that has the following options\n",
    "## {'fail', 'replace', 'append'} and the default is 'fail'\n",
    "\n",
    "## 'append' - will add new roes to the table\n",
    "conn = engine.connect().connection\n",
    "\n",
    "my_df.to_sql(name='my_users', con=engine, if_exists='append')\n",
    "\n",
    "## commit the data\n",
    "conn.commit()\n",
    "\n",
    "## Close connection \n",
    "conn.close()\n",
    "## Query the Table \n",
    "engine.execute(\"select * from my_users\").fetchall()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We see that we also get the index create, what if we don`t want the index ? \n",
    "\n",
    "## Lets drop the table and create new one but this time without the index column \n",
    "# conn = engine.connect().connection\n",
    "# engine.execute(\"drop table my_users\")\n",
    "# ## Close connection \n",
    "# conn.close()\n",
    "\n",
    "\n",
    "conn = engine.connect().connection\n",
    "\n",
    "my_df.to_sql(name='my_users', con=engine, index=False)\n",
    "\n",
    "## commit the data\n",
    "conn.commit()\n",
    "\n",
    "## Close connection \n",
    "conn.close()\n",
    "## Query the Table \n",
    "engine.execute(\"select * from my_users\").fetchall()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Great ! But we still want an index on our table, but not the default index from the DF\n",
    "\n",
    "\n",
    "\n",
    "# # Lets drop the table and create new one but this time with an index column we choose \n",
    "# conn = engine.connect().connection\n",
    "# engine.execute(\"drop table my_users\")\n",
    "# ## Close connection \n",
    "# conn.close()\n",
    "\n",
    "## We need to recreate our DF and choose the index \n",
    "\n",
    "my_df = pd.read_csv('DataSources\\my_csv.csv',index_col=['Name'])\n",
    "\n",
    "conn = engine.connect().connection\n",
    "\n",
    "my_df.to_sql(name='my_users', con=engine, index=True)\n",
    "\n",
    "## commit the data\n",
    "conn.commit()\n",
    "\n",
    "## Close connection \n",
    "conn.close()\n",
    "## Query the Table \n",
    "engine.execute(\"select * from my_users\").fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## If we want to update  some data into the same table ? \n",
    "## All we have to do is use the parameter if_exists with the option 'replace' and also we need to spcecify the \n",
    "my_df = pd.read_csv('DataSources\\my_csv.csv',index_col=['Name'])\n",
    "conn = engine.connect().connection\n",
    "\n",
    "my_df.to_sql(name='my_users', con=engine, index=True, if_exists='replace', index_label='Name' )\n",
    "\n",
    "## commit the data\n",
    "conn.commit()\n",
    "\n",
    "## Close connection \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next is to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv('DataSources\\my_csv.csv')\n",
    "\n",
    "# my_df.to_html(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\html\\to_html.html')\n",
    "\n",
    "## open the file now ! \n",
    "## very cool \n",
    "\n",
    "## now lets show what else we can do with this methods\n",
    "\n",
    "## Generate html for an ipython notebook\n",
    "# my_df.to_html(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\html\\to_html_notebook.html', notebook=True)\n",
    "\n",
    "## Remove the bold type char from the column \n",
    "# my_df.to_html(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\html\\to_html_bold.html',bold_rows=False)\n",
    "\n",
    "## Dont print the columns as header\n",
    "# my_df.to_html(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\html\\to_html_noheader.html',header=False)\n",
    "\n",
    "## Center the column Name\n",
    "# my_df.to_html(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\html\\to_html_justify.html',justify='center')\n",
    "\n",
    "## Options for justify are :\n",
    "## - left,right,center,justify,justify-all,start,end,inherit,match-parent,initial,unset\n",
    "\n",
    "\n",
    "## What about more complex formatting and bla bla bla ! \n",
    "## for this we have the classes parameter, this class definition is fetched from css file so... \n",
    "## we have a css file called my_css.css and we have class called mystyle \n",
    "# my_df.to_html(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\html\\to_html_css.html',classes='mystyle')\n",
    "\n",
    "## Hmm strange nothing happened to the html design ?! \n",
    "## if we look in the definion of the html we can see that he is pointing to the class mystyle but there is not refference \n",
    "## to the my_css.css file, so he will do nothing\n",
    "\n",
    "## Lets see what is techinique to add this my_css.css file \n",
    "\n",
    "## We will create an object called html_head, this object will wrap the output of the to_html() method\n",
    "## and will have the reffernce to the my_css.css file\n",
    "html_head = '''\n",
    "<html>\n",
    "  <head><title>HTML Pandas Dataframe with CSS</title></head>\n",
    "  <link rel=\"stylesheet\" type=\"text/css\" href=\"my_css.css\"/>\n",
    "  <body>\n",
    "    {to_html_output_table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "\n",
    "# Next we write to a file the wrapped html and we replace the placeholder with the output of the to_html()\n",
    "with open(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\html\\to_html_css.html', 'w') as f:\n",
    "    f.write(html_head.format(to_html_output_table=my_df.to_html(classes='mystyle')))\n",
    "    \n",
    "## View the html output! \n",
    "## Preatty cool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Last one is to_excel()\n",
    "\n",
    "This is used alot to send reports that can be open on most desktops and easy to share data. \n",
    "\n",
    "Lets see how it works! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we are going to use the same DF data \n",
    "\n",
    "my_df = pd.read_csv('DataSources\\my_csv.csv')\n",
    "\n",
    "\n",
    "## you probably know the name of the method already yeap is called to_excel()\n",
    "## before we start we need the module openpyxl to be installed \n",
    "\n",
    "\n",
    "# my_df.to_excel(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\excel\\my_excel.xlsx')\n",
    "\n",
    "## Cool, lets go over some of the options\n",
    "\n",
    "## Write to excell and set the name of the sheet\n",
    "# my_df.to_excel(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\excel\\my_excel.xlsx', sheet_name='cool_sheet')\n",
    "\n",
    "\n",
    "## Append a new sheet to an existing excel\n",
    "## for this task we will involve ExcelWriter() methos with mode='a' (append)\n",
    "# with pd.ExcelWriter(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\excel\\my_excel.xlsx', mode='a') as writer:\n",
    "#     my_df.to_excel(writer, sheet_name='Sheet_name_2')\n",
    "    \n",
    "## We can also append multiple sheets \n",
    "# with pd.ExcelWriter(r'C:\\Users\\adriano\\Desktop\\Projects\\Personal\\Python Pandas\\DataOut\\excel\\my_excel.xlsx', mode='a') as writer:\n",
    "#     my_df.to_excel(writer, sheet_name='Sheet_name_3')\n",
    "#     my_df.to_excel(writer, sheet_name='Sheet_name_4')\n",
    "    \n",
    "    \n",
    "# That is iit !! \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
